---
title: Camera trap distance sampling workshop
description: |
  Practical 4: model selection with overdispersed data
author:
  - name: Workshop development group
    url: https://workshops.distancesampling.org
    affiliation: CREEM, Univ of St Andrews
    affiliation_url: https://www.creem.st-andrews.ac.uk
date: "`r Sys.Date()`"
output: 
  distill::distill_article:
    toc: true
    toc_depth: 2
bibliography: howeetal18.bib
csl: apa.csl
---

```{r include=FALSE}
knitr::opts_chunk$set(eval=TRUE, echo=TRUE, message=FALSE, warnings=FALSE)
solution <- FALSE
```

# Model selection adjustments from overdispersion

Overdispersion causes AIC to select overly-complex models, so analysts should specify the number/order of adjustment terms manually when fitting distance sampling models to data from camera traps, rather than allowing automated selection using AIC. @howe_model_2019 describes two methods for performing model selection of distance sampling models in the face of overdispersion. Here we provide R functions to perform the first of these methods. The first method of @howe_model_2019 employs a two-step process.  First, an overdisersion factor $(\hat{c})$ is computed for each key function family from the most complex model in each family. The $\hat{c}$ is derived from the $\chi^2$ goodness of fit test statistic divided by its degrees of freedom. This results in an adjusted AIC score for each model in the key function family:

$$QAIC = -2 \left \{ \frac{log(\mathcal{L}(\hat{\theta}))}{\hat{c}} \right \} + 2K$$

Code to perform this QAIC computation is found in the function `qaic.pass1`:

```{r showpass1}
chat <- function(modobj) {
#  computes c-hat for a dsmodel object using Method 1 of Howe et al. (2018)
  test <- gof_ds(modobj)
  num <- test$chisquare$chi1$chisq
  denom <- test$chisquare$chi1$df
  chat <- num/denom
  return(chat)
}

qaic <- function(modobj, chat) {
#  computes QAIC for a dsmodel object given a c-hat
  value <- 2* modobj$ddf$ds$value/chat + 2 * (length(modobj$ddf$ds$pars)+1)
  return(value)
}

qaic.pass1 <- function(...) {
#   Performs Pass 1 model selection based upon Method 1 of Howe et al. (2018)
#   Arguments are dsmodel objects; assumed all based on same key function
#    c-hat is computed for the most parameter-rich model in the group
#    qaic is calculated for each model in group based upon this c-hat
#   Result returned in the form of a data.frame with model name, npar, aic and qaic
  models <- list(...)
  num.models <- length(models)
  npar <- unlist(lapply(models, function(x) length(x$ddf$ds$par)))  
  modname <-  unlist(lapply(models, function(x) x$ddf$name.message))
  aic <-  unlist(lapply(models, function(x) x$ddf$criterion))
  chat.bigmod <- chat(models[[which.max(npar)]])
  qaic <- vector(mode="numeric", length = num.models)
  for (i in 1:num.models) {
    qaic[i] <- qaic(models[[i]], chat.bigmod)
  }
  nicetab <- data.frame(modname, npar, aic, qaic)
  return(nicetab)
}
```

# Re-acquire previously fitted models

Load the `Distance` package, the previously fitted models and the flat file of peak activity duiker data.

```{r reload}
library(Distance)
data("DuikerCameraTraps")
load("C:/Users/erexs/Documents/GitHub/CTDS-pr2-duikerfit/duikermodels.RData")
```

# Compute QAIC for each set of key function models

Apply the functions defined to compute QAIC values for the half normal, uniform and hazard rate key function models.

```{r pass1, eval=solution}
hnQAIC <- qaic.pass1(hn0, hn1)
uniQAIC <- qaic.pass1(uni1, uni2)
hrQAIC <- qaic.pass1(hr0, hr1, hr2)
```
Tables of QAIC values for each key function family are shown below (code for `kable()` calls suppressed for easier readability of results).

```{r pass1a, echo=FALSE, eval=solution}
knitr::kable(hnQAIC, caption="QAIC values for half normal key models.")
```

```{r pass1b, echo=FALSE, eval=solution}
knitr::kable(uniQAIC, caption="QAIC values for uniform key models.")
```

```{r pass1c, echo=FALSE, eval=solution}
knitr::kable(hrQAIC, caption="QAIC values for hazard rate key models.")
```

From this first pass of model selection based on QAIC values, we find the preferable model with the hazard rate key function is one without adjustment terms. The model with the uniform key function preferred by QAIC has a single adjustment term; likewise for the half normal key function.

The second step of model selection ranks the models by their $\hat{c}$ values.

```{r pass2, eval=solution}
winners <- list(hn1, uni1, hr0)
chats <- unlist(lapply(winners, function(x) chat(x)))
modnames <- unlist(lapply(winners, function(x) x$ddf$name.message))
results <- data.frame(modnames, chats)
results.sort <- results[order(results$chats),]
knitr::kable(results.sort, digits=2, row.names = FALSE,
             caption="Compare with Table S5 of Howe et al. (2018)")
```

For this data set, the model chosen by this algorithm that adjusts for overdispersion is the same model (hazard rate key without adjustments) as would have been chosen by conventional model selection.

# Sensibility check for detection parameter estimates

As a check of the detection function vis-a-vis @howeetal, the paper reports the effective detection radius ($\rho$) to be 9.4m for the peak activity data set.

The effective detection radius can be derived from $\hat{P_a}$ as reported by the function `ds` as

$$\hat{\rho} = \sqrt{\hat{P_a} \cdot w^2}$$

```{r}
p_a <- hr0$ddf$fitted[1]
w <- 15
rho <- sqrt(p_a * w^2)
```

$\hat{P_a}$ is estimated to be `r round(p_a,3)`, resulting in an estimate of $\hat{\rho}$ of `r round(rho,3)`.

# Selected detection function

```{r, theplot, eval=solution}
par(mfrow=c(1,2))
plot(hr0, main="Peak activity", xlab="Distance (m)",
     showpoints=FALSE, lwd=3, xlim=c(0, 15))
plot(hr0, main="Peak activity", xlab="Distance (m)", pdf=TRUE,
     showpoints=FALSE, lwd=3, xlim=c(0, 15))
```

```{r, echo=FALSE}
par(mfrow=c(1,1))
```

## Density estimates

The camera traps do not view the entire area around them, as would be the case with simple point transect sampling. The portion of the area sampled needs to be incorporated in the estimation of abundance. The data file contains a column `multiplier` that represents the proportion of the circle sampled. @howeetal notes the camera angle of view (AOV) of 42$^{\circ}$. The proportion of the circle viewed is this value over 360$^{\circ}$.

An argument to `dht2` is `sample_fraction`, an obvious place to include this quantity.

```{r, sampfrac, eval=solution}
viewangle <- 42 # degrees
samfrac <- viewangle / 360
conversion <- convert_units("meter", NULL, "square kilometer")
peak.hr.dens <- dht2(hr0, flatfile=DuikerCameraTraps, strat_formula = ~1,
                     sample_fraction = samfrac, er_est = "P2", convert_units = conversion)
print(peak.hr.dens, report="density")
```

The density estimate uses detections from only a portion of the day (termed "peak activity" in @howeetal).  In the next practical, we examine activity patterns from the camera data to adjust density estimates for daily periods of inactivity when cameras will not trigger.

# Questions

- Explain the printed encounter rate and its standard error
- Explain the `Component percentages of variance` table at the end of the `dht2` output
  - should this be a cause for concern?
  - if it is a cause for concern, what remedy can be employed?

